{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5797,"status":"ok","timestamp":1733777408091,"user":{"displayName":"Molly Taylor","userId":"15718467291716008268"},"user_tz":300},"id":"KtPsEZT9CLXL","outputId":"fc0bb848-60f0-4b1c-afe6-7143389ec12f"},"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CPU\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete ✅ (2 CPUs, 12.7 GB RAM, 33.7/107.7 GB disk)\n"]}],"source":["#code from https://github.com/chenyicai-0611/yolov5-PASCAL-VOC\n","\n","!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt comet_ml  # install\n","\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17355,"status":"ok","timestamp":1733777426833,"user":{"displayName":"Molly Taylor","userId":"15718467291716008268"},"user_tz":300},"id":"zO10OXDhEvrm","outputId":"f0b79616-df0a-445b-fbe0-05b840432368"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 46.4M/46.4M [00:00<00:00, 101MB/s] \n"]}],"source":["# Download COCO train\n","torch.hub.download_url_to_file('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017labels.zip', 'tmp.zip')  # download (780M - 5000 images)\n","!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUHhrnuqExSu"},"outputs":[],"source":["import os\n","import glob\n","#extract images with a certain label\n","\n","def extract_detections(label_directory, label):\n","    \"\"\"\n","    Get info about knives from coco\n","\n","    label_directory: contains the label files\n","    label: label id for whatever object class\n","\n","    Returns:\n","    list: List of filenames w object detections\n","    dict: Dictionary mapping filenames to their object detection coordinates\n","    \"\"\"\n","    detected_files = []\n","    detections = {}\n","\n","    # Get all txt files in the directory\n","    label_files = glob.glob(os.path.join(label_directory, '*.txt'))\n","\n","    for label_file in label_files:\n","        with open(label_file, 'r') as f:\n","            print(label_file)\n","            lines = f.readlines()\n","\n","            # Check if any line starts with the object label\n","            object_found = False\n","            current_detections = []\n","\n","            for line in lines:\n","                values = line.strip().split()\n","                obj_label = int(float(values[0]))\n","\n","                if obj_label == label:\n","                    object_found = True\n","                    x_center = float(values[1])\n","                    y_center = float(values[2])\n","                    width = float(values[3])\n","                    height = float(values[4])\n","\n","                    current_detections.append({\n","                        'x_center': x_center,\n","                        'y_center': y_center,\n","                        'width': width,\n","                        'height': height\n","                    })\n","\n","            if object_found:\n","                base_name = os.path.splitext(os.path.basename(label_file))[0]\n","                detected_files.append(base_name)\n","                detections[base_name] = current_detections\n","\n","    return detected_files, detections\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a0-fBg2E0Iw"},"outputs":[],"source":["knife_label = 43\n","knife_files, knife_coordinates = extract_detections(\"/content/datasets/coco/labels/train2017\", knife_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1733777848773,"user":{"displayName":"Molly Taylor","userId":"15718467291716008268"},"user_tz":300},"id":"vtB2MjhYE2Ip","outputId":"add437b0-ac7d-48c4-c5cf-1531f5180df0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"source":["print(knife_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"DQ_QgPpFHzAe","outputId":"f780f67b-7371-4ba1-8b35-2223666ad590"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-12-09 19:17:56.862114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-09 19:17:56.883151: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-09 19:17:56.891369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using '/content/yolov5/.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\n","\n","Dataset not found ⚠️, missing paths ['/content/datasets/coco128/images/train2017']\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip to coco128.zip...\n","100% 6.66M/6.66M [00:00<00:00, 65.9MB/s]\n","Dataset download success ✅ (0.5s), saved to \u001b[1m/content/datasets\u001b[0m\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 127MB/s]\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n","\n","Transferred 349/349 items from yolov5s.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 737.34it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 283.41it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 167.08it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp/labels.jpg... \n","/content/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04758    0.05487    0.01544        211        640:  12% 1/8 [00:47<05:35, 48.00s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04567    0.06548    0.01514        242        640:  25% 2/8 [01:25<04:10, 41.72s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04559    0.06508    0.01713        234        640:  38% 3/8 [01:57<03:06, 37.26s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G     0.0451    0.06248     0.0179        182        640:  50% 4/8 [02:32<02:26, 36.60s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04499     0.0601    0.01852        158        640:  62% 5/8 [03:04<01:44, 34.87s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04552     0.0612    0.01792        215        640:  75% 6/8 [03:34<01:06, 33.28s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G     0.0458    0.06439    0.01782        292        640:  88% 7/8 [04:07<00:33, 33.05s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        0/2         0G    0.04529    0.06486    0.01818        194        640: 100% 8/8 [04:36<00:00, 34.62s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [01:28<00:00, 22.00s/it]\n","                   all        128        929      0.666      0.607       0.68      0.451\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04551    0.06296    0.01211        196        640:  12% 1/8 [00:29<03:26, 29.53s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04263    0.07198    0.01399        245        640:  25% 2/8 [01:04<03:16, 32.78s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04407    0.07895    0.01574        286        640:  38% 3/8 [01:35<02:40, 32.06s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04424    0.07652    0.01581        233        640:  50% 4/8 [02:08<02:09, 32.31s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G     0.0448     0.0758    0.01691        249        640:  62% 5/8 [02:41<01:37, 32.56s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04429    0.07325     0.0168        195        640:  75% 6/8 [03:12<01:04, 32.14s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04436    0.07375    0.01687        267        640:  88% 7/8 [03:46<00:32, 32.61s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        1/2         0G    0.04367    0.07196    0.01642        199        640: 100% 8/8 [04:17<00:00, 32.23s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [01:24<00:00, 21.17s/it]\n","                   all        128        929      0.726      0.622      0.711      0.479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","  0% 0/8 [00:00<?, ?it/s]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G     0.0459     0.0626    0.01277        237        640:  12% 1/8 [00:32<03:44, 32.12s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04491    0.05678    0.01539        185        640:  25% 2/8 [01:06<03:21, 33.56s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04412    0.05497    0.01566        162        640:  38% 3/8 [01:40<02:47, 33.49s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04534      0.062    0.01669        303        640:  50% 4/8 [02:12<02:12, 33.06s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04541    0.06505    0.01655        226        640:  62% 5/8 [02:45<01:39, 33.14s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04545    0.06713    0.01625        251        640:  75% 6/8 [03:17<01:05, 32.58s/it]/content/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(amp):\n","        2/2         0G    0.04545    0.06713    0.01625        251        640:  75% 6/8 [03:50<01:16, 38.39s/it]\n","Traceback (most recent call last):\n","  File \"/content/yolov5/train.py\", line 986, in <module>\n","    main(opt)\n","  File \"/content/yolov5/train.py\", line 688, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"/content/yolov5/train.py\", line 421, in train\n","    scaler.scale(loss).backward()\n","  File \"/usr/local/lib/python3.10/dist-packages/comet_ml/monkey_patching.py\", line 276, in wrapper\n","    return_value = original(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n","    _engine_run_backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n","    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : exp\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [3]                 : (1.886270523071289, 2.5453097820281982)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5 [4]      : (0.6796600313425255, 0.7109060728699843)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5:0.95 [4] : (0.45062679943855755, 0.47857560368919827)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision [4]    : (0.6661266349059719, 0.7260617117912558)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall [4]       : (0.606828045648306, 0.6223072201355642)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [4]       : (0.04367094859480858, 0.045294951647520065)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [4]       : (0.016415642574429512, 0.018176015466451645)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/obj_loss [4]       : (0.06485725939273834, 0.0719648078083992)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [4]         : (0.04047765955328941, 0.041289303451776505)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [4]         : (0.0095490962266922, 0.010753543116152287)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/obj_loss [4]         : (0.03750700503587723, 0.03828097879886627)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr0 [4]                : (0.086005, 0.0937)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr1 [4]                : (0.0007, 0.001005)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr2 [4]                : (0.0007, 0.001005)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name                        : exp\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_batch_metrics     : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_confusion_matrix  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_per_class_metrics : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_max_image_uploads     : 100\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_mode                  : online\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_model_name            : yolov5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams             : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment          : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     anchor_t            : 4.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact_alias      : latest\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size          : 16\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bbox_interval       : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box                 : 0.05\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bucket              : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg                 : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls                 : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_pw              : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste          : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees             : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device              : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     entity              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve_population   : data/hyps\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok            : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fl_gamma            : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr              : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud              : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze              : [0]\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h               : 0.015\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s               : 0.7\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v               : 0.4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|anchor_t        : 4.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|box             : 0.05\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls             : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls_pw          : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|copy_paste      : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|degrees         : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fl_gamma        : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fliplr          : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|flipud          : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_h           : 0.015\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_s           : 0.7\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_v           : 0.4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|iou_t           : 0.2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lr0             : 0.01\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lrf             : 0.01\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mixup           : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|momentum        : 0.937\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mosaic          : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj             : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj_pw          : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|perspective     : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|scale           : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|shear           : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|translate       : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_bias_lr  : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_epochs   : 3.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_momentum : 0.8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|weight_decay    : 0.0005\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_weights       : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz               : 640\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou_t               : 0.2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing     : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank          : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0                 : 0.01\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf                 : 0.01\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup               : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum            : 0.937\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic              : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                : exp\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_console      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_file         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noautoanchor        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noplots             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nosave              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noval               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj                 : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj_pw              : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer           : SGD\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience            : 100\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective         : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project             : runs/train\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     quad                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_evolve       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir            : runs/train/exp\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period         : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale               : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear               : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sync_bn             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate           : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     upload_dataset      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_conf_threshold  : 0.001\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_iou_threshold   : 0.6\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr      : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs       : 3.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum     : 0.8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay        : 0.0005\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers             : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 5 (449.46 KB)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 100\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Begin archiving the offline data.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\n","    comet upload /content/yolov5/.cometml-runs/5335d3c6ef5a41459bcaa01d00a55d7b.zip\n"]}],"source":["# Train YOLOv5s on COCO128 for 3 epochs\n","!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uMWsJpfPQR4j","outputId":"32d6eb95-1816-4160-ee76-3410a10c4362"},"outputs":[{"name":"stdout","output_type":"stream","text":["\tzip warning: name not matched: ./runs/train/exp2\n","\n","zip error: Nothing to do! (try: zip -r ./runs/train/pretrained_coco_results.zip . -i ./runs/train/exp2)\n"]}],"source":["!zip -r ./runs/train/pretrained_coco_results.zip ./runs/train/exp2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2PhmU57jScQz","outputId":"0bd05267-83dd-47f8-f03a-c9b6892fdeba"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 780M/780M [00:06<00:00, 135MB/s]\n"]}],"source":["# Download COCO test\n","torch.hub.download_url_to_file('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n","!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733775508543,"user":{"displayName":"Tara Shukla","userId":"17950463439556119622"},"user_tz":300},"id":"LkraFAslSgU5","outputId":"5af25519-8d5c-49d2-fa47-509f44063dc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CPU\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:03<00:00, 1404.59it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/val2017.cache\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   4% 7/157 [43:46<15:38:08, 375.25s/it]\n","Traceback (most recent call last):\n","  File \"/content/yolov5/val.py\", line 604, in <module>\n","    main(opt)\n","  File \"/content/yolov5/val.py\", line 575, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/val.py\", line 341, in run\n","    preds, train_out = model(im) if compute_loss else (model(im, augment=augment), None)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/yolov5/models/common.py\", line 688, in forward\n","    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/yolov5/models/yolo.py\", line 270, in forward\n","    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/content/yolov5/models/yolo.py\", line 169, in _forward_once\n","    x = m(x)  # run\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/yolov5/models/yolo.py\", line 96, in forward\n","    x[i] = self.m[i](x[i])  # conv\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n","    return F.conv2d(\n","KeyboardInterrupt\n"]}],"source":["# Validate YOLOv5s on COCO val\n","!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half --verbose"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gr7OYMM-c-GO","outputId":"b072ab85-17f7-4f3e-ed63-c0e54599ba4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.12 torch-2.5.1+cu121 CPU\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   3% 5/157 [26:07<13:31:15, 320.23s/it]"]}],"source":["# Validate YOLOv5s on COCO val\n","!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half --verbose"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g68W5B3hbCKO"},"outputs":[],"source":["!pip install fiftyone"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqaNBxsdbUbS"},"outputs":[],"source":["#https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/quickstart.ipynb#scrollTo=4D6xZJxOa7ue\n","#https://cocodataset.org/#download\n","\n","import fiftyone as fo\n","import fiftyone.zoo as foz\n","\n","#dataset = fiftyone.zoo.load_zoo_dataset(\"coco-2017\")\n","dataset = foz.load_zoo_dataset(\n","    \"coco-2017\",\n","    split=\"test\",\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdvT1R8d-BMR"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}